# routes/analysis.py
from flask_restx import Namespace, Resource, fields, reqparse
from flask_jwt_extended import jwt_required, get_jwt_identity
from flask import request, current_app
from flask_cors import cross_origin

from services import market_analysis_service
from services.historical_data_service import get_historical_data_for_symbol
from datetime import date
import datetime
import jdatetime

from werkzeug.exceptions import HTTPException

from services.fetch_latest_brsapi_eod import update_daily_eod_from_brsapi


# Ø§Ø² db Ùˆ Ø³Ø§ÛŒØ± Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø§Ø² extensions Ùˆ models ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯
from extensions import db
from models import (
    User, HistoricalData, ComprehensiveSymbolData, SignalsPerformance, FundamentalData,
    TechnicalIndicatorData, MLPrediction
)



#init Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ù„ÛŒØ³Øª.
from flask import Blueprint, jsonify
from services.symbol_initializer import populate_symbols_into_db


# Import services relevant to analysis_ns only
from services import data_fetch_and_process
from services.data_fetch_and_process import run_technical_analysis, run_candlestick_detection, populate_comprehensive_symbols

from services.ml_prediction_service import get_ml_predictions_for_symbol, get_all_ml_predictions, generate_and_save_predictions_for_watchlist

# Import func from sqlalchemy for database operations
from sqlalchemy import func 
from sqlalchemy import or_ 

analysis_ns = Namespace('analysis', description='Stock data analysis and fetching operations')


def parse_date(value):
    """
    ØªØ§Ø±ÛŒØ® Ø±Ø§ Ø§Ø² ÙØ±Ù…Øª Ø±Ø´ØªÙ‡ (YYYY-MM-DD) Ø¨Ù‡ Ø´ÛŒØ¡ datetime.date (Ù…ÛŒÙ„Ø§Ø¯ÛŒ) ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    Ø§Ú¯Ø± ÙØ±Ù…Øª Ø´Ù…Ø³ÛŒ Ø¨Ø§Ø´Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ù…ÛŒÙ„Ø§Ø¯ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    if not isinstance(value, str) or not value:
        return None
        
    # 1. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ (ISO format)
    try:
        return datetime.date.fromisoformat(value)
    except ValueError:
        pass # Ø§Ú¯Ø± Ù¾Ø§Ø±Ø³ Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯ØŒ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… Ø¨Ù‡ Ù¾Ø§Ø±Ø³ Ø´Ù…Ø³ÛŒ

    # 2. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ÛŒÙ„Ø§Ø¯ÛŒ
    try:
        # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ ÙØ±Ù…Øª Ø´Ù…Ø³ÛŒ (YYYY-MM-DD) Ø§Ø³Øª
        j_year, j_month, j_day = map(int, value.split('-'))
        # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÙ„Ø§Ø¯ÛŒ
        g_date = jdatetime.date(j_year, j_month, j_day).togregorian()
        return g_date
    except Exception:
        # Ø§Ú¯Ø± Ù¾Ø§Ø±Ø³ Ø´Ù…Ø³ÛŒ Ù‡Ù… Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯ØŒ None Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ….
        return None




# --- API Models for Flask-RESTX Documentation ---
# Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Swagger UI Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
# Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ ØªÙˆØ§Ø¨Ø¹ Ø³Ø±ÙˆÛŒØ³ Ø´Ù…Ø§ Ù…Ø·Ø§Ø¨Ù‚Øª Ø¯Ø§Ø±Ù†Ø¯.

historical_data_model = analysis_ns.model('HistoricalData', {
    'symbol_id': fields.String(required=True, description='Stock symbol ID (Persian short name)'),
    'symbol_name': fields.String(description='Stock symbol name (Persian short name)'),
    'jdate': fields.String(description='Persian date (YYYY-MM-DD)'),
    'date': fields.String(description='Gregorian date (YYYY-MM-DD)'),
    'open': fields.Float(description='Opening price'),
    'high': fields.Float(description='Highest price'),
    'low': fields.Float(description='Lowest price'),
    'close': fields.Float(description='Closing price'),
    'final': fields.Float(description='Final price'),
    'yesterday_price': fields.Float(description='Yesterday\'s closing price'),
    'volume': fields.Integer(description='Trading volume'),
    'value': fields.Float(description='Trading value'),
    'num_trades': fields.Integer(description='Number of trades'),
    'plc': fields.Float(description='Price change (last closing)'),
    'plp': fields.Float(description='Price change percentage (last closing)'),
    'pcc': fields.Float(description='Price change (final closing)'),
    'pcp': fields.Float(description='Price change percentage (final closing)'),
    'mv': fields.Float(description='Market Value'),
    'eps': fields.Float(description='Earnings Per Share'),
    'pe': fields.Float(description='Price to Earnings Ratio'),
    'buy_count_i': fields.Integer(description='Number of real buyer accounts'),
    'buy_count_n': fields.Integer(description='Number of legal buyer accounts'),
    'sell_count_i': fields.Integer(description='Number of real seller accounts'),
    'sell_count_n': fields.Integer(description='Number of legal seller accounts'),
    'buy_i_volume': fields.Integer(description='Real buyer volume'),
    'buy_n_volume': fields.Integer(description='Legal buyer volume'),
    'sell_i_volume': fields.Integer(description='Real seller volume'),
    'sell_n_volume': fields.Integer(description='Legal seller volume'),
    'zd1': fields.Integer(description='Demand count 1'),
    'qd1': fields.Integer(description='Demand volume 1'),
    'pd1': fields.Float(description='Demand price 1'),
    'zo1': fields.Integer(description='Supply count 1'),
    'qo1': fields.Integer(description='Supply volume 1'),
    'po1': fields.Float(description='Supply price 1'),
    'zd2': fields.Integer(description='Demand count 2'),
    'qd2': fields.Integer(description='Demand volume 2'),
    'pd2': fields.Float(description='Demand price 2'),
    'zo2': fields.Integer(description='Supply count 2'),
    'qo2': fields.Integer(description='Supply volume 2'),
    'po2': fields.Float(description='Supply price 2'),
    'zd3': fields.Integer(description='Demand count 3'),
    'qd3': fields.Integer(description='Demand volume 3'),
    'pd3': fields.Float(description='Demand price 3'),
    'zo3': fields.Integer(description='Supply count 3'),
    'qo3': fields.Integer(description='Supply volume 3'),
    'po3': fields.Float(description='Supply price 3'),
    'zd4': fields.Integer(description='Demand count 4'),
    'qd4': fields.Integer(description='Demand volume 4'),
    'pd4': fields.Float(description='Demand price 4'),
    'zo4': fields.Integer(description='Supply count 4'),
    'qo4': fields.Integer(description='Supply volume 4'),
    'po4': fields.Float(description='Supply price 4'),
    'zd5': fields.Integer(description='Demand count 5'),
    'qd5': fields.Integer(description='Demand volume 5'),
    'pd5': fields.Float(description='Demand price 5'),
    'zo5': fields.Integer(description='Supply count 5'),
    'qo5': fields.Integer(description='Supply volume 5'),
    'po5': fields.Float(description='Supply price 5')
})

comprehensive_symbol_data_model = analysis_ns.model('ComprehensiveSymbolData', {
    'symbol_id': fields.String(required=True, description='Stock symbol ID (Persian short name)'),
    'symbol_name': fields.String(required=True, description='Stock symbol name (Persian short name)'),
    'company_name': fields.String(description='Company name'),
    'isin': fields.String(description='ISIN code'),
    'market_type': fields.String(description='Market type'),
    'flow': fields.String(description='Flow (e.g., 1 for main market, 2 for secondary)'),
    'industry': fields.String(description='Industry name'),
    'capital': fields.String(description='Company capital'),
    'legal_shareholder_percentage': fields.Float(description='Legal Shareholder Percentage'),
    'real_shareholder_percentage': fields.Float(description='Real Shareholder Percentage'),
    'float_shares': fields.Float(description='Float shares'),
    'base_volume': fields.Float(description='Base volume'),
    'group_name': fields.String(description='Group name'),
    'description': fields.String(description='Symbol description'),
    'last_historical_update_date': fields.String(description='Last historical update date (YYYY-MM-DD)')
})

# Model for TechnicalIndicatorData
technical_indicator_model = analysis_ns.model('TechnicalIndicatorData', {
    'symbol_id': fields.String(required=True, description='Ø´Ù†Ø§Ø³Ù‡ Ù†Ù…Ø§Ø¯'),
    'jdate': fields.String(required=True, description='ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ (YYYY-MM-DD)'),
    'close_price': fields.Float(description='Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒØ§Ù†ÛŒ'),
    'RSI': fields.Float(description='Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ± RSI'),
    'MACD': fields.Float(description='Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ± MACD'),
    'MACD_Signal': fields.Float(description='Ø®Ø· Ø³ÛŒÚ¯Ù†Ø§Ù„ MACD'),
    'MACD_Hist': fields.Float(description='Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… MACD'),
    'SMA_20': fields.Float(description='Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ø³Ø§Ø¯Ù‡ Û²Û° Ø±ÙˆØ²Ù‡'),
    'SMA_50': fields.Float(description='Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ø³Ø§Ø¯Ù‡ ÛµÛ° Ø±ÙˆØ²Ù‡'),
    'Bollinger_High': fields.Float(description='Ø¨Ø§Ù†Ø¯ Ø¨Ø§Ù„Ø§ÛŒ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±'),
    'Bollinger_Low': fields.Float(description='Ø¨Ø§Ù†Ø¯ Ù¾Ø§ÛŒÛŒÙ† Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±'),
    'Bollinger_MA': fields.Float(description='Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ø¨Ø§Ù†Ø¯ Ø¨ÙˆÙ„ÛŒÙ†Ú¯Ø±'),
    'Volume_MA_20': fields.Float(description='Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Ø­Ø¬Ù… Û²Û° Ø±ÙˆØ²Ù‡'),
    'ATR': fields.Float(description='Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ± ATR'),
    # New indicators added to the model
    'Stochastic_K': fields.Float(description='Stochastic Oscillator %K'),
    'Stochastic_D': fields.Float(description='Stochastic Oscillator %D'),
    'squeeze_on': fields.Boolean(description='ÙˆØ¶Ø¹ÛŒØª Squeeze Momentum'),
    'halftrend_signal': fields.Integer(description='Ø³ÛŒÚ¯Ù†Ø§Ù„ HalfTrend (1 Ø¨Ø±Ø§ÛŒ Ø®Ø±ÛŒØ¯)'),
    'resistance_level_50d': fields.Float(description='Ø³Ø·Ø­ Ù…Ù‚Ø§ÙˆÙ…Øª ÛµÛ° Ø±ÙˆØ²Ù‡'),
    'resistance_broken': fields.Boolean(description='Ø¢ÛŒØ§ Ù…Ù‚Ø§ÙˆÙ…Øª Ø´Ú©Ø³ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª')
})

# Model for FundamentalData
fundamental_data_model = analysis_ns.model('FundamentalData', {
    'symbol_id': fields.String(required=True, description='Stock symbol ID (Persian short name)'),
    'last_updated': fields.DateTime(description='Last update timestamp'),
    'eps': fields.Float(description='Earnings Per Share'),
    'pe_ratio': fields.Float(description='Price-to-Earnings Ratio'),
    'group_pe_ratio': fields.Float(description='Group Price-to-Earnings Ratio'),
    'psr': fields.Float(description='Price-to-Sales Ratio (PSR)'),
    'p_s_ratio': fields.Float(description='Price-to-Sales Ratio (P/S)'),
    'market_cap': fields.Float(description='Market Capitalization'),
    'base_volume': fields.Float(description='Base Volume'),
    'float_shares': fields.Float(description='Float Shares')
})

# NEW: Model for ML Predictions (ADDED)
ml_prediction_model = analysis_ns.model('MLPredictionModel', {
    'id': fields.Integer(readOnly=True, description='The unique identifier of the prediction'),
    'symbol_id': fields.String(required=True, description='The ID of the stock symbol'),
    'symbol_name': fields.String(required=True, description='The name of the stock symbol'),
    'prediction_date': fields.String(required=True, description='Gregorian date when the prediction was made (YYYY-MM-DD)'),
    'jprediction_date': fields.String(required=True, description='Jalali date when the prediction was made (YYYY-MM-DD)'),
    'prediction_period_days': fields.Integer(description='Number of days for the prediction horizon'),
    'predicted_trend': fields.String(required=True, description='Predicted trend: UP, DOWN, or NEUTRAL'),
    'prediction_probability': fields.Float(required=True, description='Probability/confidence of the predicted trend (0.0 to 1.0)'),
    'predicted_price_at_period_end': fields.Float(description='Optional: Predicted price at the end of the period'),
    'actual_price_at_period_end': fields.Float(description='Actual price at the end of the prediction period'),
    'actual_trend_outcome': fields.String(description='Actual trend outcome: UP, DOWN, or NEUTRAL'),
    'is_prediction_accurate': fields.Boolean(description='True if predicted_trend matches actual_trend_outcome'),
    'signal_source': fields.String(description='Source of the signal, e.g., ML-Trend'),
    'model_version': fields.String(description='Version of the ML model used for prediction'),
    'created_at': fields.String(description='Timestamp of creation'),
    'updated_at': fields.String(description='Timestamp of last update'),
})

# =================================================================================
# --- Parsers for API Endpoints ---
# =================================================================================

populate_symbols_parser = reqparse.RequestParser()
populate_symbols_parser.add_argument('batch_size', 
                                     type=int, 
                                     required=False, 
                                     help='ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± Ù‡Ø± Ø¯Ø³ØªÙ‡ (Batch) Ø§Ø² TSETMC Ø®ÙˆØ§Ù†Ø¯Ù‡ Ùˆ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø«Ø¨Øª Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 200.', 
                                     default=200, # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ù‡ 200 ØªØºÛŒÛŒØ± ÛŒØ§ÙØª
                                     location='json')


update_parser = reqparse.RequestParser()
update_parser.add_argument('limit', type=int, default=200, help='Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± Ù‡Ø± Ø§Ø¬Ø±Ø§')
# **ØªÙˆØ¬Ù‡:** Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ± specific_symbols_listØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ø§ÛŒÙ† Ù¾Ø§Ø±Ø³Ø± Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯.

repair_parser = reqparse.RequestParser()
repair_parser.add_argument('data_type', type=str, default='all', choices=['all', 'historical', 'technical', 'fundamental'], help='Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ±Ù…ÛŒÙ…')
repair_parser.add_argument('limit', type=int, default=50, help='Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ±Ù…ÛŒÙ…')

# âœ… FIX: Ø§ÛŒÙ† Ù¾Ø§Ø±Ø³Ø± Ø§Ú©Ù†ÙˆÙ† Ø¯Ø± Ø¬Ø§ÛŒÚ¯Ø§Ù‡ ØµØ­ÛŒØ­ Ùˆ Ù‚Ø¨Ù„ Ø§Ø² Ø§ÙˆÙ„ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø§Ø³Øª.
historical_data_parser = reqparse.RequestParser()
historical_data_parser.add_argument('days', type=int, default=61, help='ØªØ¹Ø¯Ø§Ø¯ **Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ** (Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ) Ø§Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ ÙˆØ§Ú©Ø´ÛŒ. Ø§Ú¯Ø± start_date Ùˆ end_date Ø¨Ø§Ø´Ù†Ø¯ØŒ Ø§ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ± Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.')
historical_data_parser.add_argument('start_date', type=str, help='ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø²Ù‡ (YYYY-MM-DD) Ø´Ù…Ø³ÛŒ ÛŒØ§ Ù…ÛŒÙ„Ø§Ø¯ÛŒ') # âœ… Ø¬Ø¯ÛŒØ¯: Ø§Ø´Ø§Ø±Ù‡ Ø¨Ù‡ Ø´Ù…Ø³ÛŒ ÛŒØ§ Ù…ÛŒÙ„Ø§Ø¯ÛŒ
historical_data_parser.add_argument('end_date', type=str, help='ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ù¾Ø§ÛŒØ§Ù† Ø¨Ø§Ø²Ù‡ (YYYY-MM-DD) Ø´Ù…Ø³ÛŒ ÛŒØ§ Ù…ÛŒÙ„Ø§Ø¯ÛŒ') # âœ… Ø¬Ø¯ÛŒØ¯: Ø§Ø´Ø§Ø±Ù‡ Ø¨Ù‡ Ø´Ù…Ø³ÛŒ ÛŒØ§ Ù…ÛŒÙ„Ø§Ø¯ÛŒ


# ğŸ†• Ù¾Ø§Ø±Ø³Ø± Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§Øª Full Refresh
full_refresh_parser = reqparse.RequestParser()
full_refresh_parser.add_argument(
    'specific_symbols', 
    type=list, 
    location='json', 
    required=False, 
    help='Ù„ÛŒØ³Øª Ù†Ø§Ù… Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ø´Ø®ØµÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ Ø±ÙˆØ² Ø±Ø³Ø§Ù†ÛŒ Ø´ÙˆÙ†Ø¯ (Ù…Ø«Ø§Ù„: ["Ø®ÙˆØ¯Ø±Ùˆ", "Ø®Ø³Ø§Ù¾Ø§"]). Ø§Ú¯Ø± Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯ØŒ ØªÙ…Ø§Ù… Ù†Ù…Ø§Ø¯Ù‡Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.'
)



# --- API Resources ---

# =================================================================================
# --- Section 1: Task Execution Endpoints ---
# =================================================================================


@analysis_ns.route('/stock-history/<string:symbol_input>') # ØªØºÛŒÛŒØ± Ù†Ø§Ù… Ù…ØªØºÛŒØ± Ø¨Ù‡ symbol_input
@analysis_ns.param('symbol_input', 'Ø´Ù†Ø§Ø³Ù‡ ÛŒØ§ Ù†Ø§Ù… Ù†Ù…Ø§Ø¯ (Ù…Ø«Ø§Ù„: Ø®ÙˆØ¯Ø±Ùˆ)')
class StockHistoryResource(Resource):
    @analysis_ns.doc(security='Bearer Auth', parser=historical_data_parser)
    @jwt_required()
    @analysis_ns.response(200, 'Historical data fetched successfully')
    @analysis_ns.response(400, 'Invalid date format')
    @analysis_ns.response(404, 'No data found for symbol')
    def get(self, symbol_input): # ØªØºÛŒÛŒØ± Ù†Ø§Ù… Ù…ØªØºÛŒØ± Ø¨Ù‡ symbol_input
        """
        ÙˆØ§Ú©Ø´ÛŒ Ø³Ø§Ø¨Ù‚Ù‡ Ù…Ø¹Ø§Ù…Ù„Ø§Øª (Historical Data) ÛŒÚ© Ù†Ù…Ø§Ø¯ Ù…Ø´Ø®Øµ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª ÙÛŒÙ„ØªØ± Ø²Ù…Ø§Ù†ÛŒ.
        """
        try:
            args = historical_data_parser.parse_args()
            days = args['days']
            start_date_str = args['start_date']
            end_date_str = args['end_date']
            
            start_date = parse_date(start_date_str)
            end_date = parse_date(end_date_str)

            if (start_date_str and start_date is None) or (end_date_str and end_date is None):
                analysis_ns.abort(400, "Invalid date format. Please use YYYY-MM-DD (Gregorian or Jalali).")

            # ğŸš€ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ Ø³Ø±ÙˆÛŒØ³
            history_data = get_historical_data_for_symbol(
                symbol_input, # Ø§Ø² symbol_input Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
                start_date=start_date, 
                end_date=end_date, 
                days=days
            )
            
            if history_data is None:
                current_app.logger.error(f"Service returned None for {symbol_input}")
                analysis_ns.abort(500, "Internal server error during data retrieval. Service returned None.")

            if not history_data:
                # Ø§ÛŒÙ† Ø®Ø· Ø¨Ø§Ø¹Ø« Ø§ÛŒØ¬Ø§Ø¯ 404 Ù…ÛŒâ€ŒØ´ÙˆØ¯.
                analysis_ns.abort(404, f"No historical data found for symbol: {symbol_input} in the specified range.")

            return {"history": history_data}, 200
            
        except HTTPException as e:
            # âœ… FIX: Ø§Ú¯Ø± Ø®Ø·Ø§ ÛŒÚ© Ø®Ø·Ø§ÛŒ HTTP (Ù…Ø«Ù„ 404 ÛŒØ§ 400) Ø¨Ø§Ø´Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø¨Ø§Ù„Ø§ Ù…ÛŒâ€ŒØ§Ù†Ø¯Ø§Ø²ÛŒÙ….
            raise e
            
        except Exception as e:
            # Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯ÛŒÚ¯Ø± (Ù…Ø«Ù„ Ø®Ø·Ø§ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÛŒØ§ Ù…Ù†Ø·Ù‚ÛŒ)
            current_app.logger.error(f"An unexpected critical error occurred for {symbol_input}: {e}", exc_info=True)
            analysis_ns.abort(500, f"An unexpected critical error occurred: {str(e)}")






@analysis_ns.route('/initial-populate')
class InitialPopulationResource(Resource):
    @analysis_ns.doc(security='Bearer Auth', description="Ø§Ø¬Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³. Ø§ÛŒÙ† Ø¹Ù…Ù„ÛŒØ§Øª Ø³Ù†Ú¯ÛŒÙ† Ø§Ø³Øª Ùˆ ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø± Ø¨Ø§ÛŒØ¯ Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯.")
    @jwt_required()
    def post(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø§ ØªÙ…Ø§Ù… Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ"""
        try:
            result = data_fetch_and_process.initial_populate_all_symbols_and_data(db.session)
            return {"message": "Initial population process completed successfully.", "details": result}, 200
        except Exception as e:
            current_app.logger.error(f"Error during initial population: {e}", exc_info=True)
            return {"message": f"An error occurred: {str(e)}"}, 500



# NEW: Endpoint Ø¨Ø±Ø§ÛŒ Ù¾Ø± Ú©Ø±Ø¯Ù† Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§
@analysis_ns.route('/populate-symbols')
class PopulateSymbolsResource(Resource):
    @analysis_ns.doc(security='Bearer Auth', 
                      description="ÙÙ‚Ø· Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø±Ø§ Ø§Ø² Ø¨ÙˆØ±Ø³ Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯Ù‡ Ùˆ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¯Ø±Ø¬/Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø§ÛŒÙ† Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ 200 ØªØ§ÛŒÛŒ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
    @jwt_required()
    @analysis_ns.expect(populate_symbols_parser)
    def post(self):
        """Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±"""
        args = populate_symbols_parser.parse_args()
        # ğŸ’¡ ØªØºÛŒÛŒØ± Ø§Ø² limit Ø¨Ù‡ batch_size
        batch_size = args.get('batch_size')
        
        try:
            # ğŸ’¡ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù‡Ù…Ø§Ù† ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ± batch_size
            result = data_fetch_and_process.populate_comprehensive_symbols(db.session, batch_size=batch_size)
            
            return {
                "message": "Symbol list population completed successfully.", 
                "details": result
            }, 200
            
        except Exception as e:
            current_app.logger.error(f"Error during symbol population: {e}", exc_info=True)
            db.session.rollback()
            # ğŸ’¡ Ø¨Ù‡ØªØ± Ø§Ø³Øª Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ Ø±Ø§ Ø§Ø² Ø³Ù…Øª Ø¨Ú©â€ŒØ§Ù†Ø¯ (Ú©Ù‡ Ø¯Ø± Ø¢Ù† Read timed out Ù…Ø¯ÛŒØ±ÛŒØª Ø´Ø¯Ù‡) Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯.
            return {"message": f"An error occurred: {str(e)}"}, 500


# --- NEW: BRSAPI EOD Update and Analysis Endpoint (The new daily flow) ---
@analysis_ns.route('/run-brsapi-eod-flow')
class BRSAPIEODFlowResource(Resource):
    @analysis_ns.doc(security='Bearer Auth', 
                     description="ÙØ±Ø§ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ EOD Ø±ÙˆØ²Ø§Ù†Ù‡: ÙÚ† Ø¯Ø§Ø¯Ù‡ Ø§Ø² BRSAPIØŒ Ø°Ø®ÛŒØ±Ù‡ØŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ùˆ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ. Ø§ÛŒÙ† Ù…Ø³ÛŒØ± ÙˆØ¸ÛŒÙÙ‡ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ Historical/Technical Ø±Ø§ Ø¨Ø± Ø¹Ù‡Ø¯Ù‡ Ø¯Ø§Ø±Ø¯.")
    @jwt_required()
    def post(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¬Ø±ÛŒØ§Ù† Ú©Ø§Ù…Ù„ Ø¢Ù¾Ø¯ÛŒØª EOD Ø§Ø² BRSAPI"""
        today = date.today()
        results = {
            "eod_brsapi": {"count": 0, "message": ""},
            "technical_analysis": {"count": 0, "message": "N/A"},
            "candlestick_detection": {"count": 0, "message": "N/A"},
            "update_status": "Failed"
        }

        try:
            # 1. ğŸš€ ÙÚ† Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ EOD Ø§Ø² BRSAPI
            # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ update_daily_eod_from_brsapi Ø®Ø±ÙˆØ¬ÛŒ (count, message, list_of_updated_symbol_ids) Ø¯Ø§Ø±Ø¯.
            eod_count, eod_msg, updated_symbol_ids = update_daily_eod_from_brsapi(db.session)
            results['eod_brsapi']['count'] = eod_count
            results['eod_brsapi']['message'] = eod_msg
            
            # 2. âš¡ï¸ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø±Ø§Ø­Ù„ Ø¨Ø¹Ø¯ÛŒ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø¨Ù‡â€ŒØ±ÙˆØ² Ø´Ø¯Ù‡
            if eod_count > 0:
                # 2.1. Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
                tech_count, tech_msg = run_technical_analysis(
                    db.session,
                    symbols_list=updated_symbol_ids # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² symbol_id Ø¯Ø§Ø®Ù„ÛŒ
                )
                results['technical_analysis']['count'] = tech_count
                results['technical_analysis']['message'] = tech_msg

                # 2.2. ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ
                candlestick_count = run_candlestick_detection(
                    db.session, 
                    symbols_list=updated_symbol_ids # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² symbol_id Ø¯Ø§Ø®Ù„ÛŒ
                )
                results['candlestick_detection']['count'] = candlestick_count
                results['candlestick_detection']['message'] = f"âœ… ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {candlestick_count} Ù†Ù…Ø§Ø¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯."
                
                # 2.3. Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªØ§Ø±ÛŒØ® Ø¢Ù¾Ø¯ÛŒØª Ø¯Ø± ComprehensiveSymbolData (Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÚ©Ø±Ø§Ø± Ø§Ø¬Ø±Ø§ Ø¯Ø± run-daily-update)
                symbols_to_update = db.session.query(ComprehensiveSymbolData).filter(
                    ComprehensiveSymbolData.symbol_id.in_(updated_symbol_ids)
                ).all()
                
                for symbol in symbols_to_update:
                    symbol.last_historical_update_date = today # ØªÙ†Ø¸ÛŒÙ… Ø¨Ù‡ Ø§Ù…Ø±ÙˆØ²
                
                db.session.commit()
                results['update_status'] = f"Success: {len(updated_symbol_ids)} symbol status updated."

            elif "Ù‚Ø¨Ù„Ø§Ù‹ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ ÙÚ†â€ŒØ´Ø¯Ù‡ Ø«Ø¨Øª Ø´Ø¯Ù‡ Ø§Ø³Øª" in eod_msg:
                results['update_status'] = "Already Updated"
            
            final_message = (
                f"ğŸ BRSAPI EOD Flow completed. "
                f"EOD: {eod_count}, "
                f"Technical: {results['technical_analysis']['count']}, "
                f"Candlestick: {results['candlestick_detection']['count']}."
            )
            current_app.logger.info(final_message)
            
            return results, 200

        except Exception as e:
            current_app.logger.error(f"âŒ Critical error during BRSAPI EOD Flow: {e}", exc_info=True)
            db.session.rollback() 
            results['update_status'] = "Failed due to critical error."
            return {"message": f"An error occurred: {str(e)}", "results": results}, 500

# Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ú©Ù„ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ùˆ ÙØ§Ù†Ø¯ÛŒÙ…Ù†ØªØ§Ù„ Ùˆ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ
@analysis_ns.route('/full-historical-refresh')
class FullHistoricalRefreshResource(Resource):
    @analysis_ns.doc(security='Bearer Auth', parser=full_refresh_parser, description="âš ï¸ Ø§ÛŒÙ† Ø¹Ù…Ù„ÛŒØ§Øª Ø´Ø§Ù…Ù„ **Ø­Ø°Ù Ú©Ø§Ù…Ù„ (TRUNCATE)** Ø¬Ø¯ÙˆÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ùˆ Ø¯Ø±Ø¬ Ù…Ø¬Ø¯Ø¯ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¨Ú†â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø³Øª.")
    @jwt_required()
    @analysis_ns.response(200, 'Full historical data refresh completed successfully.')
    @analysis_ns.response(500, 'Internal server error during refresh operation.')
    def post(self):
        """
        Ø§Ø¬Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ùˆ ÙØ§Ù†Ø¯Ø§Ù…Ù†ØªØ§Ù„ (TRUNCATE + Bulk Insert).
        """
        try:
            # âš ï¸ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ ØªØ§Ø¨Ø¹ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ import Ø´Ø¯Ù‡ Ø§Ø³Øª
            from services.fetch_full_historical_pytse import fetch_full_historical_pytse
            from extensions import db
            from flask import current_app

            args = full_refresh_parser.parse_args()
            symbols_list = args.get('specific_symbols')

            # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ Ø³Ø±ÙˆÛŒØ³
            record_count, message = fetch_full_historical_pytse(
                db.session,
                symbols_to_update=symbols_list
            )
            
            return {
                "message": "Full historical and fundamental data refresh completed.", 
                "details": message,
                "records_inserted": record_count
            }, 200
            
        except Exception as e:
            db.session.rollback()
            current_app.logger.error(f"Error during full historical data refresh: {e}", exc_info=True)
            analysis_ns.abort(500, f"An unexpected critical error occurred: {str(e)}")




# --- NEW: Daily Update Endpoint ---
@analysis_ns.route('/run-daily-update')
class DailyUpdateResource(Resource):
    @analysis_ns.doc(security='Bearer Auth', description="Ø§Ø¬Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø³Ø¨Ú© Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù¾Ø³ Ø§Ø² Ù¾Ø§ÛŒØ§Ù† Ø¨Ø§Ø²Ø§Ø±.")
    @jwt_required()
    @analysis_ns.expect(update_parser)
    def post(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ù¾Ø¯ÛŒØª Ø³Ø¨Ú© Ø±ÙˆØ²Ø§Ù†Ù‡"""
        args = update_parser.parse_args()
        try:
            # 1. Ø¯Ø³ØªØ±Ø³ÛŒ Ø§ÛŒÙ…Ù† Ø¨Ù‡ limit
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² hasattr Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² AttributeError Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ limit Ø¯Ø± update_parser ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
            limit_val = args.limit if hasattr(args, 'limit') and args.limit is not None else 200
            
            # 2. Ø¯Ø³ØªØ±Ø³ÛŒ Ø§ÛŒÙ…Ù† Ø¨Ù‡ specific_symbols_list
            specific_symbols_list_val = args.specific_symbols_list if hasattr(args, 'specific_symbols_list') else None
            
            # â›” limit_per_run Ùˆ update_fundamental Ø§Ø² Ø§ÛŒÙ†Ø¬Ø§ Ø­Ø°Ù Ø´Ø¯Ù†Ø¯ ØªØ§ Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ ØªØ§Ø¨Ø¹ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯
            
            # ğŸš€ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
            result = data_fetch_and_process.run_daily_update(
                db_session=db.session, 
                limit=limit_val,
                specific_symbols_list=specific_symbols_list_val
                # update_fundamental=True Ùˆ limit_per_run Ø­Ø°Ù Ø´Ø¯Ù†Ø¯
            )
            
            # Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù†ØªÛŒØ¬Ù‡
            return {
                "message": "Daily update process completed (Historical, Technical, and Fundamental check).",
                "results": result 
            }, 200
        except Exception as e:
            current_app.logger.error(f"Error during daily update: {e}", exc_info=True)
            db.session.rollback() 
            return {"message": f"An error occurred: {str(e)}"}, 500


# --- REVISED: Maintenance Update Endpoint (Formerly Full Update) ---
@analysis_ns.route('/run-maintenance-update')
class MaintenanceUpdateResource(Resource):
    @analysis_ns.doc(security='Bearer Auth', description="Ø§Ø¬Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ Ùˆ Ø³Ù†Ú¯ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ú¯Ø§Ù…â€ŒØ³Ø§Ø²ÛŒ Ú©Ù„ÛŒØŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ù‡ÙØªÚ¯ÛŒ ÛŒØ§ Ù…Ø§Ù‡Ø§Ù†Ù‡.")
    @jwt_required()
    @analysis_ns.expect(update_parser)
    def post(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ù¾Ø¯ÛŒØª Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ùˆ Ù‡Ù…Ú¯Ø§Ù…â€ŒØ³Ø§Ø²ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ"""
        args = update_parser.parse_args()
        try:
            result = data_fetch_and_process.run_full_data_update(db.session, limit_per_run=args['limit'])
            return {"message": "Full maintenance update completed.", "details": result}, 200
        except Exception as e:
            current_app.logger.error(f"Error during maintenance update: {e}", exc_info=True)
            return {"message": f"An error occurred: {str(e)}"}, 500


# =================================================================================
# --- Section 2: Maintenance & Status Endpoints ---
# =================================================================================

# --- NEW: Status Report Endpoint ---
@analysis_ns.route('/status-report')
class StatusReportResource(Resource):
    @analysis_ns.doc(security='Bearer Auth', description="Ø¯Ø±ÛŒØ§ÙØª ÛŒÚ© Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¢Ù†â€ŒÙ‡Ø§.")
    @jwt_required()
    def get(self):
        """Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        success, report = data_fetch_and_process.get_status_report()
        if success:
            return report, 200
        else:
            return {"message": report}, 500

# --- NEW: Data Repair Endpoint ---
@analysis_ns.route('/repair-data')
class RepairDataResource(Resource):
    @analysis_ns.doc(security='Bearer Auth', description="Ø§Ø¬Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ ØªØ±Ù…ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ùˆ Ù¾Ø± Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ ÛŒØ§ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡.")
    @jwt_required()
    @analysis_ns.expect(repair_parser)
    def post(self):
        """ØªØ±Ù…ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ"""
        args = repair_parser.parse_args()
        success, message = data_fetch_and_process.run_data_repair(data_type=args['data_type'], limit=args['limit'])
        if success:
            return {"message": message}, 200
        else:
            return {"message": message}, 500

# --- NEW: Cleanup Duplicates Endpoint ---
@analysis_ns.route('/cleanup-duplicates')
class CleanupDuplicatesResource(Resource):
    @analysis_ns.doc(security='Bearer Auth', description="Ø§Ø¬Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø§Ø² Ø¬Ø¯Ø§ÙˆÙ„ Ø¯Ø§Ø¯Ù‡.")
    @jwt_required()
    def post(self):
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ"""
        success, message = data_fetch_and_process.run_cleanup_duplicates()
        if success:
            return {"message": message}, 200
        else:
            return {"message": message}, 500


# =================================================================================
# --- Section 3: Data Retrieval Endpoints ---
# (These endpoints are mostly unchanged but kept for completeness)
# =================================================================================

@analysis_ns.route('/historical-data/<string:symbol_input>')
@analysis_ns.param('symbol_input', 'Ø´Ù†Ø§Ø³Ù‡ ÛŒØ§ Ù†Ø§Ù… Ù†Ù…Ø§Ø¯ (Ù…Ø«Ø§Ù„: Ø®ÙˆØ¯Ø±Ùˆ)')
class HistoricalDataResource(Resource):
    @jwt_required()
    @analysis_ns.doc(security='Bearer Auth', parser=historical_data_parser)
    @analysis_ns.marshal_list_with(historical_data_model)
    def get(self, symbol_input):
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯ Ù…Ø´Ø®Øµ (Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø±ÙˆÛŒØ³)"""
        try:
            args = historical_data_parser.parse_args()
            days = args['days']
            start_date_str = args['start_date']
            end_date_str = args['end_date']
            
            start_date = parse_date(start_date_str)
            end_date = parse_date(end_date_str)

            if (start_date_str and start_date is None) or (end_date_str and end_date is None):
                analysis_ns.abort(400, "Invalid date format. Please use YYYY-MM-DD (Gregorian or Jalali).")
                
            # ğŸš€ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø±ÙˆÛŒØ³ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            history_data = get_historical_data_for_symbol(
                symbol_input, 
                start_date=start_date, 
                end_date=end_date, 
                days=days
            )
            
            if not history_data:
                analysis_ns.abort(404, f"No historical data found for symbol: {symbol_input}")
                
            return history_data
            
        except HTTPException as e:
            raise e
        except Exception as e:
            current_app.logger.error(f"An unexpected critical error occurred in HistoricalDataResource for {symbol_input}: {e}", exc_info=True)
            analysis_ns.abort(500, f"An unexpected critical error occurred: {str(e)}")


@analysis_ns.route('/technical-indicators/<string:symbol_input>')
@analysis_ns.param('symbol_input', 'Ø´Ù†Ø§Ø³Ù‡ ÛŒØ§ Ù†Ø§Ù… Ù†Ù…Ø§Ø¯ (Ù…Ø«Ø§Ù„: Ø®ÙˆØ¯Ø±Ùˆ)')
class TechnicalIndicatorsResource(Resource):
    @jwt_required()
    @analysis_ns.doc(security='Bearer Auth')
    @analysis_ns.marshal_list_with(technical_indicator_model)
    def get(self, symbol_input):
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…Ø§Ø¯ Ù…Ø´Ø®Øµ"""
        # Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ Ø±Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯ Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØºÛŒÛŒØ± Ø¨Ù‡ get_historical_data_for_symbol Ù†Ø¯Ø§Ø±Ø¯.
        # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡ ÛŒÚ© Ø³Ø±ÙˆÛŒØ³ get_technical_data_for_symbol Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯.
        records = TechnicalIndicatorData.query.join(ComprehensiveSymbolData, TechnicalIndicatorData.symbol_id == ComprehensiveSymbolData.id)\
            .filter(ComprehensiveSymbolData.symbol_name == symbol_input)\
            .order_by(TechnicalIndicatorData.jdate.desc()).all()
        if not records:
            analysis_ns.abort(404, f"No technical indicators found for symbol: {symbol_input}")
        return records






@analysis_ns.route('/fundamental_data/<string:symbol_input>')
@analysis_ns.param('symbol_input', 'The stock symbol ID (Persian short name) or ISIN')
class FundamentalDataResource(Resource):
    @jwt_required()
    @analysis_ns.marshal_with(fundamental_data_model)
    @analysis_ns.response(200, 'Fundamental data fetched successfully')
    @analysis_ns.response(404, 'No fundamental data found for the symbol')
    @analysis_ns.doc(security='Bearer Auth')
    def get(self, symbol_input):
        """Fetches fundamental data for a given stock symbol."""
        symbol_id = data_fetch_and_process.get_symbol_id(symbol_input)
        if not symbol_id:
            analysis_ns.abort(404, f"Invalid symbol ID or name: {symbol_input}")

        fundamental_data = FundamentalData.query.filter_by(symbol_id=symbol_id).first()
        if not fundamental_data:
            # Attempt to fetch and save fundamental data if not found in DB
            # This now calls the specific update_fundamental_data function
            success, msg = data_fetch_and_process.update_fundamental_data(symbol_id, symbol_id) 
            if success:
                fundamental_data = FundamentalData.query.filter_by(symbol_id=symbol_id).first()
                if fundamental_data:
                    return fundamental_data, 200
            analysis_ns.abort(404, f"No fundamental data found for symbol_id: {symbol_id} after attempted fetch.")
        return fundamental_data

@analysis_ns.route('/trigger_fundamental_update/<string:symbol_input>')
@analysis_ns.param('symbol_input', 'The stock symbol ID (Persian short name) or ISIN')
class TriggerFundamentalUpdate(Resource):
    @jwt_required()
    @analysis_ns.response(200, 'Fundamental data update triggered successfully')
    @analysis_ns.response(500, 'Error during fundamental data update')
    @analysis_ns.doc(security='Bearer Auth')
    def post(self, symbol_input):
        """Trigger update for fundamental data for a symbol."""
        
        try:
            # ğŸ’¥ Ø§ØµÙ„Ø§Ø­ 1: Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø³Ø´Ù† Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØªÙˆØ§Ø¨Ø¹ Ø³Ø±ÙˆÛŒØ³
            with data_fetch_and_process.get_session_local() as db_session:
                
                # ğŸ’¥ Ø§ØµÙ„Ø§Ø­ 2: Ø§Ø±Ø³Ø§Ù„ db_session Ø¨Ù‡ get_symbol_id (Ø±ÙØ¹ TypeError)
                symbol_id = data_fetch_and_process.get_symbol_id(db_session, symbol_input)
                
                if not symbol_id:
                    analysis_ns.abort(404, f"Invalid symbol ID or name: {symbol_input}")

                current_app.logger.info(f"Triggered fundamental data update for symbol: {symbol_input} (ID: {symbol_id}).")
                
                # ğŸ’¥ Ø§ØµÙ„Ø§Ø­ 3: ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØµØ­ÛŒØ­ ØªØ§Ø¨Ø¹ Ø¢Ù¾Ø¯ÛŒØª Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ± Ù†Ù…Ø§Ø¯ Ø®Ø§Øµ
                fund_count, fund_msg = data_fetch_and_process.update_symbol_fundamental_data(
                    db_session=db_session,
                    specific_symbols_list=[symbol_input],
                    limit=1
                )
                
                if fund_count > 0:
                    return {"message": fund_msg}, 200
                else:
                    # Ø§Ú¯Ø± Ø³Ø±ÙˆÛŒØ³ Ø¢Ù¾Ø¯ÛŒØª Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ù†ØªÙˆØ§Ù†Ø³Øª Ø¢Ù¾Ø¯ÛŒØª Ú©Ù†Ø¯ Ø§Ù…Ø§ Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ Ø¯Ø§Ø¯
                    return {"message": fund_msg}, 500

        except Exception as e:
            current_app.logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± API Ø¢Ù¾Ø¯ÛŒØª Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ {symbol_input}: {e}", exc_info=True)
            analysis_ns.abort(500, f"Critical error during fundamental data update: {e}")




@analysis_ns.route('/analyze_technical_indicators/<string:symbol_input>')
@analysis_ns.param('symbol_input', 'The stock symbol ID (Persian short name) or ISIN')
@analysis_ns.param('days', 'Number of recent days to fetch and analyze (default: 365)')
class TechnicalIndicatorsResource(Resource):
    @jwt_required()
    @analysis_ns.marshal_list_with(technical_indicator_model)
    @analysis_ns.response(200, 'Technical indicators calculated successfully')
    @analysis_ns.response(404, 'No historical data found for the symbol')
    @analysis_ns.doc(security='Bearer Auth')
    def get(self, symbol_input):
        """
        Fetches historical data, calculates various technical indicators,
        saves them to the database, and returns the recent results.
        """
        symbol_id = data_fetch_and_process.get_symbol_id(symbol_input)
        if not symbol_id:
            analysis_ns.abort(404, f"Invalid symbol ID or name: {symbol_input}")

        # âœ… FIX: ØªØ¨Ø¯ÛŒÙ„ symbol_id Ø¨Ù‡ Ø±Ø´ØªÙ‡ Ø¨Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒ Ú¯Ø±ÙØªÙ† Ø§Ø² DB
        # Ø§ÛŒÙ† Ú©Ø§Ø± Ù…Ø·Ø§Ø¨Ù‚Øª Ø¨Ø§ Ù†ÙˆØ¹ db.String Ø¯Ø± Ù…Ø¯Ù„ TechnicalIndicatorData Ø±Ø§ ØªØ¶Ù…ÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        symbol_id_str = str(symbol_id)

        parser = reqparse.RequestParser()
        parser.add_argument('days', type=int, default=365, help='Number of recent days to fetch and analyze')
        args = parser.parse_args()
        days = args['days']

        # Call the service function to analyze and save technical data
        # symbol_id (integer/original type) Ø¨Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ Ø³Ø±ÙˆÛŒØ³ ÙØ±Ø³ØªØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        success, msg = data_fetch_and_process.analyze_technical_data_for_symbol(symbol_id, symbol_id, limit_days=days)
        if not success:
            analysis_ns.abort(404, f"Failed to analyze technical data for symbol_id: {symbol_id}. Reason: {msg}")

        # Fetch the newly saved technical data from the database
        # âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² symbol_id_str (Ù…Ù‚Ø¯Ø§Ø± Ø±Ø´ØªÙ‡â€ŒØ§ÛŒ) Ø¯Ø± ÙÛŒÙ„ØªØ±
        technical_data_records = TechnicalIndicatorData.query.filter_by(symbol_id=symbol_id_str)\
                                                     .order_by(TechnicalIndicatorData.jdate.desc())\
                                                     .limit(days).all()
        
        if not technical_data_records:
            analysis_ns.abort(404, f"No technical indicator data found for symbol_id: {symbol_id}. This might indicate a saving issue.")

        # Convert records to a list of dictionaries for marshalling
        return [rec.__dict__ for rec in technical_data_records]


# --- NEW API Resource for ML Predictions ---
@analysis_ns.route('/ml-predictions')
class MLPredictionListResource(Resource):
    @analysis_ns.doc(security='Bearer Auth', params={'symbol_id': 'Optional: Filter predictions by symbol ID'})
    @jwt_required()
    @analysis_ns.marshal_list_with(ml_prediction_model)
    @analysis_ns.response(200, 'ML predictions retrieved successfully.')
    @analysis_ns.response(404, 'No ML prediction found for the symbol (if symbol_id provided).')
    @analysis_ns.response(500, 'Error retrieving ML predictions.')
    def get(self):
        """
        Retrieves ML predictions. Can be filtered by symbol_id.
        If no symbol_id is provided, returns all predictions.
        """
        symbol_id = request.args.get('symbol_id')
        if symbol_id:
            current_app.logger.info(f"API request for ML prediction for symbol: {symbol_id}")
            prediction = get_ml_predictions_for_symbol(symbol_id)
            if prediction:
                # get_ml_predictions_for_symbol returns a single dict, marshal_list_with expects a list
                return [prediction], 200 
            else:
                return {'message': f'No ML prediction found for symbol_id: {symbol_id}'}, 404
        else:
            current_app.logger.info("API request for all ML predictions.")
            predictions = get_all_ml_predictions()
            return predictions, 200





#init Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ù„ÛŒØ³Øª.
@analysis_ns.route('/init-symbols')
class InitSymbolsResource(Resource):
    @jwt_required()
    def post(self):
        """Initialize symbols in database"""
        count, msg = populate_symbols_into_db()
        return {
            "success": True if count > 0 else False,
            "message": msg,
            "count": count
        }, 200

#For Debug
@analysis_ns.route('/debug/tehran-stocks-structure')
class DebugTehranStocksStructureResource(Resource):
    def get(self):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ tehran-stocks"""
        from services.symbol_initializer import debug_tehran_stocks_structure
        df = debug_tehran_stocks_structure()
        
        if df is not None and not df.empty:
            return {
                'columns': list(df.columns),
                'row_count': len(df),
                'sample_data': df.iloc[0].to_dict() if not df.empty else {}
            }, 200
        else:
            return {'error': 'Failed to fetch data from tehran-stocks'}, 500




# Market Summary
@analysis_ns.route('/market-summary')
class MarketSummaryResource(Resource):
    def get(self):
        """
        Generates and returns a structured summary of the market analysis.
        Provides a daily or weekly report in JSON format.
        """
        current_app.logger.info("API request for market summary.")
        
        # âœ… Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø§Ú©Ù†ÙˆÙ† ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ú©Ø§Ù…Ù„ (Ù†Ù‡ ÙÙ‚Ø· Ù…ØªÙ†) Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯
        summary_data = market_analysis_service.generate_market_summary()
        
        # âœ… Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø±Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯. 
        # Flask-RESTX Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¢Ù† Ø±Ø§ Ø¨Ù‡ JSON ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        return summary_data, 200
