# -*- coding: utf-8 -*-
# services/market_analysis_service.py

import logging
from datetime import datetime, timedelta, date
import jdatetime
from sqlalchemy.exc import SQLAlchemyError
import json
from typing import Dict, List, Any, Optional
import pandas as pd
import numpy as np


from models import (
    ComprehensiveSymbolData,
    HistoricalData,
    TechnicalIndicatorData,
    GoldenKeyResult,
    AggregatedPerformance,
    WeeklyWatchlistResult,
    DailySectorPerformance, # ğŸ‘ˆ ØªØºÛŒÛŒØ± Û±: Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù…Ø¯Ù„ DailySectorPerformance
)


# Import Jinja2 for templating
from jinja2 import Environment, FileSystemLoader, Template

# Import necessary modules and models from the Flask application structure
from extensions import db
from services.iran_market_data import fetch_iran_market_indices
from services.utils import calculate_smart_money_flow

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯
logger = logging.getLogger(__name__)

# -----------------------------------------------------------------------------
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Jinja2: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±
# -----------------------------------------------------------------------------

# ØªØ¹Ø±ÛŒÙ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù‚Ø§Ù„Ø¨ Ø¯Ø± Ø³Ø·Ø­ Ù…Ø§Ú˜ÙˆÙ„
daily_template = None
weekly_template = None

try:
    template_loader = FileSystemLoader('services/templates')
    template_env = Environment(loader=template_loader)
    daily_template = template_env.get_template('daily_summary.j2')
    weekly_template = template_env.get_template('weekly_summary.j2')
    logger.info("âœ… Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Jinja2 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯.")
except Exception as e:
    logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Jinja2 Ø§Ø² ÙØ§ÛŒÙ„: {e}. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÙˆÙ†â€ŒØ­Ø§ÙØ¸Ù‡â€ŒØ§ÛŒ.", exc_info=True)

    # Fallback to in-memory templates for robustness
    DAILY_TEMPLATE_STRING = """
**ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§Ø²Ø§Ø± Ø¨ÙˆØ±Ø³ ØªÙ‡Ø±Ø§Ù† - {{ jdate }}**

## Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø±
**Ø´Ø§Ø®Øµ Ú©Ù„:** Ø¨Ø§ ØªØºÛŒÛŒØ± **{{ '%.2f'|format(indices_data.Total_Index.percent|default(0)) }}%**ØŒ Ø§Ù…Ø±ÙˆØ² Ø±ÙˆÙ†Ø¯ÛŒ {{ indices_data.Total_Index.status }} Ø±Ø§ ØªØ¬Ø±Ø¨Ù‡ Ú©Ø±Ø¯.
**Ø´Ø§Ø®Øµ Ù‡Ù…â€ŒÙˆØ²Ù†:** Ø¹Ù…Ù„Ú©Ø±Ø¯ {{ indices_data.Equal_Weighted_Index.status }} Ø¢Ù† Ø¨Ø§ ØªØºÛŒÛŒØ± **{{ '%.2f'|format(indices_data.Equal_Weighted_Index.percent|default(0)) }}%** Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø³Ù‡Ø§Ù… Ú©ÙˆÚ†Ú© Ùˆ Ù…ØªÙˆØ³Ø· Ø¨ÙˆØ¯.
{{ smart_money_flow_text }}

{{ sector_summary }} ğŸ‘ˆ ØªØºÛŒÛŒØ± Û³: Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† Ø®Ù„Ø§ØµÙ‡ ØµÙ†Ø§ÛŒØ¹ Ø¨Ù‡ Ù‚Ø§Ù„Ø¨ Ø±ÙˆØ²Ø§Ù†Ù‡

## ØªØ­Ù„ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ù†ØªØ®Ø¨
{% if all_symbols %}
Ø¯Ø± Ø§Ø¯Ø§Ù…Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ÛŒ Ú©Ù‡ Ø§Ù…Ø±ÙˆØ² Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ØŒ Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª:
{{ symbols_text }}
{% else %}
Ø§Ù…Ø±ÙˆØ² Ù†Ù…Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¯Ø± Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒØ¯Ù‡ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.
{% endif %}
"""
    WEEKLY_TEMPLATE_STRING = """
**ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø¨ÙˆØ±Ø³ ØªÙ‡Ø±Ø§Ù† - {{ jdate }}**

## Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø±
{% if indices_data %}
**Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§:** Ø´Ø§Ø®Øµ Ú©Ù„ Ø¯Ø± Ø§ÛŒÙ† Ù‡ÙØªÙ‡ **{{ '%.2f'|format(indices_data.total_profit_percent|default(0)) }}%** Ùˆ Ø´Ø§Ø®Øµ Ù‡Ù…â€ŒÙˆØ²Ù† (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù…Ù„Ú©Ø±Ø¯ GoldenKey) **{{ '%.2f'|format(indices_data.win_rate|default(0)) }}%** Ù†Ø±Ø® Ø¨Ø±Ø¯ Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª.
{% else %}
Ø®Ù„Ø§ØµÙ‡ Ø±ÙˆÙ†Ø¯ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.
{% endif %}
{{ smart_money_flow_text }}

{{ sector_summary }} ğŸ‘ˆ ØªØºÛŒÛŒØ± Û³: Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† Ø®Ù„Ø§ØµÙ‡ ØµÙ†Ø§ÛŒØ¹ Ø¨Ù‡ Ù‚Ø§Ù„Ø¨ Ù‡ÙØªÚ¯ÛŒ

## Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ù†ØªØ®Ø¨ Ù‡ÙØªÙ‡
{% if all_symbols %}
Ø¯Ø± Ø§Ø¯Ø§Ù…Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± Ø·ÙˆÙ„ Ù‡ÙØªÙ‡ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª:
{{ symbols_text }}
{% else %}
Ø¯Ø± Ø§ÛŒÙ† Ù‡ÙØªÙ‡ Ù‡ÛŒÚ† Ù†Ù…Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¯Ø± Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒØ¯Ù‡ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.
{% endif %}
"""
    daily_template = Template(DAILY_TEMPLATE_STRING)
    weekly_template = Template(WEEKLY_TEMPLATE_STRING)
    logger.info("âœ… Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Jinja2 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÙˆÙ†â€ŒØ­Ø§ÙØ¸Ù‡â€ŒØ§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯.")

# -----------------------------------------------------------------------------
# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¬Ø¯ÛŒØ¯ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡
# -----------------------------------------------------------------------------

def _safe_dataframe_from_orm(rows: List[Any], cols: List[str]) -> pd.DataFrame:
    """
    DataFrame Ø§ÛŒÙ…Ù† Ø§Ø² Ù„ÛŒØ³Øª Ø§Ø´ÛŒØ§Ø¡ ORM Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯ Ùˆ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ SQLAlchemy Ø±Ø§ Ø­Ø°Ù Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    if not rows:
        return pd.DataFrame(columns=cols)
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
    data = [{c: getattr(r, c, None) for c in cols} for r in rows]
    return pd.DataFrame(data)

def _choose_price_col(df: pd.DataFrame) -> str:
    """
    Ø³ØªÙˆÙ† Ù…Ù†Ø§Ø³Ø¨ Ù‚ÛŒÙ…Øª Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø­Ø¬Ù… Ø¨Ù‡ Ø§Ø±Ø²Ø´ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯: close > close_price > pclosing.
    """
    for c in ('close', 'close_price', 'pclosing'):
        if c in df.columns and df[c].mean() > 0:
            return c
    # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ø³ØªÙˆÙ† Ù‚ÛŒÙ…ØªÛŒ Ù…Ù†Ø§Ø³Ø¨ Ù†Ø¨ÙˆØ¯
    df['dummy_price'] = 1000 
    return 'dummy_price'

def _get_day_type() -> str:
    """
    Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ (Ø±ÙˆØ²Ø§Ù†Ù‡ØŒ Ù‡ÙØªÚ¯ÛŒ ÛŒØ§ Ø¨Ø¯ÙˆÙ† ØªØ­Ù„ÛŒÙ„) Ù…Ø´Ø®Øµ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    Ø¯Ø± Ø§ÛŒØ±Ø§Ù†: Ø´Ù†Ø¨Ù‡ ØªØ§ Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡ (ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡) | Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡ (Ø¨Ø¯ÙˆÙ† ØªØ­Ù„ÛŒÙ„) | Ø¬Ù…Ø¹Ù‡ (ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ).
    """
    # jdatetime.date.today().weekday() -> Monday=0, ..., Sunday=6.
    # Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨ÛŒØ´ØªØ±ØŒ Ø§Ø² Ù†Ø§Ù… Ø±ÙˆØ² ÙØ§Ø±Ø³ÛŒ ÛŒØ§ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….
    j_today = jdatetime.date.today()
    day_name = j_today.strftime('%A') 

    # Sat: 5, Sun: 6, Mon: 0, Tue: 1, Wed: 2, Thu: 3, Fri: 4
    if day_name in ('Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday'):
        return 'daily'
    if day_name == 'Friday':
        return 'weekly'
    if day_name == 'Thursday':
        return 'no_analysis_day'
        
    return 'daily' # Fallback

def _calculate_pnl(entry_price: float, exit_price: Optional[float]) -> Optional[float]:
    """
    Ø¯Ø±ØµØ¯ Ø³ÙˆØ¯ ÛŒØ§ Ø²ÛŒØ§Ù† Ø±Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    if not entry_price or entry_price == 0 or exit_price is None:
        return None
    return round(((exit_price - entry_price) / entry_price) * 100, 2)

def _get_formatted_smart_money_flow_text(net_flow: float, is_weekly: bool) -> str:
    """Ù…ØªÙ† ÙØ±Ù…Øªâ€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙˆØ¶Ø¹ÛŒØª ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬ Ù¾ÙˆÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    period = "Ø§Ù…Ø±ÙˆØ²" if not is_weekly else "Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹ Ø§ÛŒÙ† Ù‡ÙØªÙ‡"
    # 1e10 = 10,000,000,000 Ø±ÛŒØ§Ù„ = 1 Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù†
    if net_flow > 0:
        return f"{period} Ø´Ø§Ù‡Ø¯ ÙˆØ±ÙˆØ¯ Ù¾ÙˆÙ„ Ø­Ù‚ÛŒÙ‚ÛŒ Ø¨Ù‡ Ø§Ø±Ø²Ø´ ØªÙ‚Ø±ÛŒØ¨ÛŒ **{net_flow / 1e10:.2f} Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù†** Ø¨Ù‡ Ø¨Ø§Ø²Ø§Ø± Ø¨ÙˆØ¯ÛŒÙ…."
    elif net_flow < 0:
        return f"{period} Ø®Ø±ÙˆØ¬ Ù¾ÙˆÙ„ Ø­Ù‚ÛŒÙ‚ÛŒ Ø¨Ù‡ Ø§Ø±Ø²Ø´ ØªÙ‚Ø±ÛŒØ¨ÛŒ **{abs(net_flow) / 1e10:.2f} Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù†** Ø§Ø² Ø¨Ø§Ø²Ø§Ø± ØµÙˆØ±Øª Ú¯Ø±ÙØª."
    else:
        return f"{period} Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„ Ø­Ù‚ÛŒÙ‚ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ø§Ø± ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ Ø®Ù†Ø«ÛŒ Ø¨ÙˆØ¯."

def _get_formatted_symbols_text(symbols: List[Any], is_weekly: bool) -> str:
    """Ù…ØªÙ† ÙØ±Ù…Øªâ€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ØªØ­Ù„ÛŒÙ„ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ù†ØªØ®Ø¨ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    text_parts = []
    for symbol_data in symbols:
        symbol_name = symbol_data.symbol_name
        # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… symbol_data Ø§Ø² Ù†ÙˆØ¹ WeeklyWatchlistResult Ø§Ø³Øª
        signal_source = getattr(symbol_data, 'signal_source', 'WeeklyWatchlist')
        reasons = getattr(symbol_data, 'reasons', '{}')
        if not isinstance(reasons, str):
            reasons = json.dumps(reasons, ensure_ascii=False)
        entry_price = symbol_data.entry_price

        if not is_weekly:
            daily_change = getattr(symbol_data, 'daily_change_percent', None)
            
            status_text = ""
            if daily_change is not None:
                if daily_change > 0:
                    status_text = f"Ø¨Ø§ Ø±Ø´Ø¯ **{daily_change:.2f}%** Ù‡Ù…Ø±Ø§Ù‡ Ø¨ÙˆØ¯."
                elif daily_change < 0:
                    status_text = f"Ø¨Ø§ Ú©Ø§Ù‡Ø´ **{abs(daily_change):.2f}%** Ù‡Ù…Ø±Ø§Ù‡ Ø¨ÙˆØ¯."
                else:
                    status_text = "Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù‚ÛŒÙ…Øª Ø¨Ø³ØªÙ‡ Ø´Ø¯."
            else:
                status_text = "ØªØºÛŒÛŒØ±Ø§Øª Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¢Ù† Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

            text_parts.append(f"**- Ù†Ù…Ø§Ø¯ {symbol_name} ({signal_source}):** {status_text} (Ø¯Ù„ÛŒÙ„ Ø³ÛŒÚ¯Ù†Ø§Ù„: {reasons})")
        else:
            pnl_percent = getattr(symbol_data, 'profit_loss_percentage', None)
            
            status_text = ""
            if pnl_percent is not None:
                if pnl_percent > 0:
                    status_text = f"Ø§ÛŒÙ† Ù‡ÙØªÙ‡ **{pnl_percent:.2f}%** Ø³ÙˆØ¯Ø¯Ù‡ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª."
                elif pnl_percent < 0:
                    status_text = f"Ø§ÛŒÙ† Ù‡ÙØªÙ‡ Ø¨Ø§ **{abs(pnl_percent):.2f}%** Ø²ÛŒØ§Ù† Ø¨Ø³ØªÙ‡ Ø´Ø¯."
                else:
                    status_text = "Ø§ÛŒÙ† Ù‡ÙØªÙ‡ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù‚ÛŒÙ…Øª Ø¨Ø³ØªÙ‡ Ø´Ø¯."
            else:
                status_text = "Ù‡Ù†ÙˆØ² Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ø§Ù„ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª."
            
            text_parts.append(f"**- Ù†Ù…Ø§Ø¯ {symbol_name}:** {status_text} (Ø¯Ù„ÛŒÙ„ Ø³ÛŒÚ¯Ù†Ø§Ù„: {reasons})")
            
    return "\n".join(text_parts)

def _prepare_indices_data(indices_data: Dict) -> Dict:
    """Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù‚Ø§Ù„Ø¨ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    processed_data = {}
    for key, value in indices_data.items():
        percent = value.get('percent', 0) or 0
        status = 'ØµØ¹ÙˆØ¯ÛŒ' if percent > 0 else 'Ù†Ø²ÙˆÙ„ÛŒ' if percent < 0 else 'Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±'
        processed_data[key] = {'percent': percent, 'status': status}
    return processed_data

def _get_top_sectors_summary(db_session: db.session, limit: int = 5) -> str: # ğŸ‘ˆ ØªØºÛŒÛŒØ± Û²: ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯
    """
    Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø§Ø² {{ limit }} ØµÙ†Ø¹Øª Ø¨Ø±ØªØ± Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø®Ø±ÛŒÙ† Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    try:
        # 1. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† ØªØ§Ø±ÛŒØ® ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯
        latest_date_record = db_session.query(DailySectorPerformance.jdate).order_by(DailySectorPerformance.jdate.desc()).first()
        if not latest_date_record:
            return "\n## Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØµÙ†Ø§ÛŒØ¹\n**Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØµÙ†Ø§ÛŒØ¹ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.**"

        latest_jdate_str = latest_date_record[0]
        
        # 2. ÙˆØ§Ú©Ø´ÛŒ ØµÙ†Ø§ÛŒØ¹ Ø¨Ø±ØªØ± Ø¨Ø±Ø§ÛŒ Ø¢Ù† ØªØ§Ø±ÛŒØ®
        top_sectors = DailySectorPerformance.query.filter_by(
            jdate=latest_jdate_str
        ).order_by(DailySectorPerformance.rank.asc()).limit(limit).all()
        
        if not top_sectors:
            return "\n## Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØµÙ†Ø§ÛŒØ¹\n**Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØµÙ†Ø§ÛŒØ¹ Ø§Ù…Ø±ÙˆØ² ØªÚ©Ù…ÛŒÙ„ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.**"
            
        text_parts = []
        for sector in top_sectors:
            # Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ: 1, 2, 3, ...
            # Ø¬Ø§Ø¨Ø¬Ø§ÛŒÛŒ Ù¾ÙˆÙ„: Ø§Ø² Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù† Ø¨Ù‡ 2 Ø±Ù‚Ù… Ø§Ø¹Ø´Ø§Ø±
            flow_billion_toman = sector.net_money_flow / 1e10 if sector.net_money_flow else 0
            
            flow_status = "ÙˆØ±ÙˆØ¯ Ù¾ÙˆÙ„" if flow_billion_toman > 0 else "Ø®Ø±ÙˆØ¬ Ù¾ÙˆÙ„"
            flow_value = f"{abs(flow_billion_toman):.2f}"
            
            text_parts.append(
                f"- **{sector.rank}.** {sector.sector_name}: {flow_status} ({flow_value} Ù….ØªÙˆÙ…Ø§Ù†)"
            )

        header = f"\n## Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ {limit} ØµÙ†Ø¹Øª Ø¨Ø±ØªØ± (ØªØ§Ø±ÛŒØ® ØªØ­Ù„ÛŒÙ„: {latest_jdate_str})\n"
        return header + "\n".join(text_parts)
    
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ ØµÙ†Ø§ÛŒØ¹ Ø¨Ø±ØªØ±: {e}")
        return "\n## Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØµÙ†Ø§ÛŒØ¹\n**Ø®Ø·Ø§ÛŒ ÙÙ†ÛŒ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØµÙ†Ø§ÛŒØ¹.**"

# -----------------------------------------------------------------------------
# ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ØªØ­Ù„ÛŒÙ„
# -----------------------------------------------------------------------------

def _generate_daily_summary() -> str:
    """
    ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù…Ø®ØªØµØ± Ø§Ø² Ø¨Ø§Ø²Ø§Ø± Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚Ø§Ù„Ø¨ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ *Ø¬Ø¯ÛŒØ¯* Ù‡Ù…Ø§Ù† Ø±ÙˆØ² Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
    """
    logger.info("Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§Ø²Ø§Ø±...")
    
    try:
        # 1. Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ø§Ø² Ù…Ù†Ø¨Ø¹ Ø¢Ù†Ù„Ø§ÛŒÙ†
        raw_indices_data = fetch_iran_market_indices()
        indices_data = _prepare_indices_data(raw_indices_data)
        
        # 1.1. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† ØªØ§Ø±ÛŒØ® Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
        last_trading_day_data = HistoricalData.query.filter(
            HistoricalData.symbol_name.isnot(None)
        ).order_by(HistoricalData.jdate.desc()).first()
        
        if not last_trading_day_data:
            logger.error("âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ ØªØ§Ø±ÛŒØ®ÛŒ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return "âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."
            
        analysis_date_jdate_str = last_trading_day_data.jdate
        
        current_jdate_str = jdatetime.date.today().strftime('%Y-%m-%d')

        if current_jdate_str != analysis_date_jdate_str:
            logger.info("Ø¨Ø§Ø²Ø§Ø± Ø§Ù…Ø±ÙˆØ² (%s) Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø³ØªÙ‡ Ø¨Ø§Ø´Ø¯ ÛŒØ§ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ (%s) ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯.", 
                         current_jdate_str, analysis_date_jdate_str)
        
        # 2. ØªÙ†Ø¸ÛŒÙ… ØªØ§Ø±ÛŒØ® Ø¨Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ùˆ ØªØ§Ø±ÛŒØ® Ø¯ÛŒØ±ÙˆØ²
        yesterday_data = HistoricalData.query.filter(
            HistoricalData.jdate < analysis_date_jdate_str
        ).order_by(HistoricalData.jdate.desc()).first()
        
        yesterday_jdate_str = yesterday_data.jdate if yesterday_data else None

        # 2. Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„
        historical_data_for_df_cols = ['symbol_id', 'symbol_name', 'jdate', 'close', 'close_price', 'pclosing',
                                        'buy_i_volume', 'sell_i_volume', 'buy_count_i', 'sell_count_i', 'value']
        
        historical_data_for_df_rows = HistoricalData.query.with_entities(
            *[getattr(HistoricalData, col) for col in historical_data_for_df_cols if hasattr(HistoricalData, col)]
        ).filter(
            HistoricalData.jdate == analysis_date_jdate_str, 
            HistoricalData.symbol_name.isnot(None)
        ).all()
        
        # **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² helper Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ø§ÛŒÙ…Ù† DataFrame**
        df = _safe_dataframe_from_orm(historical_data_for_df_rows, historical_data_for_df_cols)
        
        if df.empty:
            logger.warning("âŒ DataFrame Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² %s Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.", analysis_date_jdate_str)
            total_net_real_money_flow = 0
        else:
            # 1. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            for col in ['buy_i_volume', 'sell_i_volume', 'close', 'close_price', 'pclosing', 'value', 'buy_count_i', 'sell_count_i']:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
            # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ calculate_smart_money_flow
            smart_money_flow_df = calculate_smart_money_flow(df)

            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¬Ø±ÛŒØ§Ù† Ø®Ø§Ù„Øµ Ø­Ø¬Ù…ÛŒ (robust logic)
            if smart_money_flow_df is not None and 'individual_net_flow' in smart_money_flow_df.columns and len(smart_money_flow_df) == len(df):
                net_volume_flow = smart_money_flow_df['individual_net_flow']
            else:
                net_volume_flow = df['buy_i_volume'] - df['sell_i_volume']

            # ÛŒØ§ÙØªÙ† Ø³ØªÙˆÙ† Ù‚ÛŒÙ…Øª Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø±Ø²Ø´ Ø±ÛŒØ§Ù„ÛŒ
            price_col = _choose_price_col(df)
            df['net_real_value_flow'] = net_volume_flow * df[price_col]
            total_net_real_money_flow = df['net_real_value_flow'].sum()
        
        # 3. Ø¯Ø±ÛŒØ§ÙØª Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ù‡Ù…Ø§Ù† Ø±ÙˆØ² Ø§Ø² Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡
        # **GoldenKeyResults Ø­Ø°Ù Ø´Ø¯ - ØªÙ…Ø±Ú©Ø² ÙÙ‚Ø· Ø¨Ø± WeeklyWatchlist**
        weekly_watchlist_results = WeeklyWatchlistResult.query.filter(WeeklyWatchlistResult.jentry_date == analysis_date_jdate_str).all() 
        
        all_new_symbols = weekly_watchlist_results

        # 4. Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØºÛŒÛŒØ±Ø§Øª Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² _calculate_pnl
        for symbol in all_new_symbols:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 'close' Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù‚ÛŒÙ…Øª Ù…Ø±Ø¬Ø¹ ÙˆØ±ÙˆØ¯/Ø®Ø±ÙˆØ¬
            today_data = HistoricalData.query.filter_by(symbol_id=symbol.symbol_id, jdate=analysis_date_jdate_str).first() 
            
            if yesterday_jdate_str:
                yesterday_data = HistoricalData.query.filter_by(symbol_id=symbol.symbol_id, jdate=yesterday_jdate_str).first()

                if today_data and yesterday_data and yesterday_data.close is not None and today_data.close is not None:
                    # **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² _calculate_pnl**
                    daily_change = _calculate_pnl(yesterday_data.close, today_data.close)
                    
                    setattr(symbol, 'daily_change_percent', daily_change)
                else:
                    setattr(symbol, 'daily_change_percent', None)
            else:
                setattr(symbol, 'daily_change_percent', None)

        
        # 5. **Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ­Ù„ÛŒÙ„ ØµÙ†Ø§ÛŒØ¹** ğŸ‘ˆ ØªØºÛŒÛŒØ± Û´: ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯
        sector_summary_text = _get_top_sectors_summary(db.session, limit=5)

        # 6. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ù‚Ø§Ù„Ø¨
        data_for_template = {
            'jdate': analysis_date_jdate_str, 
            'indices_data': indices_data,
            'smart_money_flow_text': _get_formatted_smart_money_flow_text(total_net_real_money_flow, is_weekly=False),
            'sector_summary': sector_summary_text, # ğŸ‘ˆ Ù…ØªØºÛŒØ± Ø¬Ø¯ÛŒØ¯
            'all_symbols': all_new_symbols,
            'symbols_text': _get_formatted_symbols_text(all_new_symbols, is_weekly=False)
        }
        
        # **Ø§ØµÙ„Ø§Ø­: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² **kwargs Ø¨Ø±Ø§ÛŒ render**
        return daily_template.render(**data_for_template)

    except SQLAlchemyError as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡: {e}", exc_info=True)
        return "âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ØŒ Ø§Ù…Ú©Ø§Ù† ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡: {e}", exc_info=True)
        return "âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ ÙÙ†ÛŒØŒ Ø§Ù…Ú©Ø§Ù† ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."

def _generate_weekly_summary() -> str:
    """
    ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ Ø¬Ø§Ù…Ø¹ Ø§Ø² Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ø§Ø²Ø§Ø± Ùˆ Ù†Ù…Ø§Ø¯Ù‡Ø§ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    logger.info("Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø§Ø²Ø§Ø±...")
    
    try:
        week_ago_greg = datetime.now().date() - timedelta(days=7)
        week_ago_jdate_str = jdatetime.date.fromgregorian(date=week_ago_greg).strftime('%Y-%m-%d')
        
        # 1. Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ¬Ù…ÛŒØ¹ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯
        aggregated_data = AggregatedPerformance.query.filter(
            AggregatedPerformance.period_type == 'weekly'
        ).order_by(AggregatedPerformance.created_at.desc()).first()
        
        # **ØªØ¨Ø¯ÛŒÙ„ Ø´ÛŒ ORM Ø¨Ù‡ dict Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù‚Ø§Ù„Ø¨**
        if aggregated_data:
            indices_for_template = {
                'total_profit_percent': getattr(aggregated_data, 'total_profit_percent', 0),
                'win_rate': getattr(aggregated_data, 'win_rate', 0),
            }
        else:
            indices_for_template = {}
        
        # 2. Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ HistoricalData Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¬Ø±ÛŒØ§Ù† Ù¾ÙˆÙ„
        historical_data_for_df_cols = ['symbol_id', 'symbol_name', 'jdate', 'close', 'close_price', 'pclosing',
                                        'buy_i_volume', 'sell_i_volume', 'buy_count_i', 'sell_count_i', 'value']
        
        historical_data_for_df_rows = HistoricalData.query.with_entities(
            *[getattr(HistoricalData, col) for col in historical_data_for_df_cols if hasattr(HistoricalData, col)]
        ).filter(
            HistoricalData.jdate >= week_ago_jdate_str,
            HistoricalData.symbol_name.isnot(None)
        ).all()
        
        # **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² helper Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ø§ÛŒÙ…Ù† DataFrame**
        df = _safe_dataframe_from_orm(historical_data_for_df_rows, historical_data_for_df_cols)

        if df.empty:
            logger.warning("âŒ DataFrame Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ Ù‡ÙØªÚ¯ÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
            total_net_real_money_flow = 0
        else:
            # 1. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            for col in ['buy_i_volume', 'sell_i_volume', 'close', 'close_price', 'pclosing', 'value', 'buy_count_i', 'sell_count_i']:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
            # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ calculate_smart_money_flow
            weekly_smart_money_flow_df = calculate_smart_money_flow(df)
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¬Ø±ÛŒØ§Ù† Ø®Ø§Ù„Øµ Ø­Ø¬Ù…ÛŒ (robust logic)
            if weekly_smart_money_flow_df is not None and 'individual_net_flow' in weekly_smart_money_flow_df.columns and len(weekly_smart_money_flow_df) == len(df):
                net_volume_flow = weekly_smart_money_flow_df['individual_net_flow']
            else:
                net_volume_flow = df['buy_i_volume'] - df['sell_i_volume']

            # ÛŒØ§ÙØªÙ† Ø³ØªÙˆÙ† Ù‚ÛŒÙ…Øª Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø±Ø²Ø´ Ø±ÛŒØ§Ù„ÛŒ
            price_col = _choose_price_col(df)
            df['net_real_value_flow'] = net_volume_flow * df[price_col]
            total_net_real_money_flow = df['net_real_value_flow'].sum()

        # 3. Ø¯Ø±ÛŒØ§ÙØª Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙØªÙ‡ 
        # **GoldenKeyRecords Ø­Ø°Ù Ø´Ø¯ - ØªÙ…Ø±Ú©Ø² ÙÙ‚Ø· Ø¨Ø± WeeklyWatchlist**
        weekly_watchlist_records = WeeklyWatchlistResult.query.filter(WeeklyWatchlistResult.jentry_date >= week_ago_jdate_str).all()
        
        all_week_symbols = weekly_watchlist_records
        
        # 4. **Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ­Ù„ÛŒÙ„ ØµÙ†Ø§ÛŒØ¹** ğŸ‘ˆ ØªØºÛŒÛŒØ± Û´: ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯
        sector_summary_text = _get_top_sectors_summary(db.session, limit=5)
        
        # 5. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ù‚Ø§Ù„Ø¨
        data_for_template = {
            'jdate': jdatetime.date.today().strftime('%Y-%m-%d'),
            'indices_data': indices_for_template, # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ØªØ¨Ø¯ÛŒÙ„â€ŒØ´Ø¯Ù‡
            'smart_money_flow_text': _get_formatted_smart_money_flow_text(total_net_real_money_flow, is_weekly=True),
            'sector_summary': sector_summary_text, # ğŸ‘ˆ Ù…ØªØºÛŒØ± Ø¬Ø¯ÛŒØ¯
            'all_symbols': all_week_symbols,
            'symbols_text': _get_formatted_symbols_text(all_week_symbols, is_weekly=True)
        }
        
        # **Ø§ØµÙ„Ø§Ø­: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² **kwargs Ø¨Ø±Ø§ÛŒ render**
        return weekly_template.render(**data_for_template)

    except SQLAlchemyError as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ: {e}", exc_info=True)
        return "âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ØŒ Ø§Ù…Ú©Ø§Ù† ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ: {e}", exc_info=True)
        return "âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ ÙÙ†ÛŒØŒ Ø§Ù…Ú©Ø§Ù† ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."

# -----------------------------------------------------------------------------
# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø³Ø±ÙˆÛŒØ³
# -----------------------------------------------------------------------------

def generate_market_summary() -> str:
    """
    ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø³Ø±ÙˆÛŒØ³ Ú©Ù‡ Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ø±ÙˆØ² Ù‡ÙØªÙ‡ØŒ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ ÛŒØ§ Ù‡ÙØªÚ¯ÛŒ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    logger.info("Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø´Ø¯.")
    day_type = _get_day_type()
    
    if day_type == 'daily':
        return _generate_daily_summary()
    elif day_type == 'weekly':
        return _generate_weekly_summary()
    elif day_type == 'no_analysis_day':
        logger.info("Ø§Ù…Ø±ÙˆØ² Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡ Ø§Ø³ØªØ› ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ù…Ù†ØªØ´Ø± Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        return "Ø¯Ø± Ø±ÙˆØ² Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡ØŒ Ø¨Ø§Ø²Ø§Ø± Ø³Ø±Ù…Ø§ÛŒÙ‡ ÙØ¹Ø§Ù„ Ù†ÛŒØ³Øª Ùˆ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù…Ù†ØªØ´Ø± Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯."
    
    return "Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ø¬Ø§Ø±ÛŒ Ù‚Ø§Ø¨Ù„ ØªØ´Ø®ÛŒØµ Ù†ÛŒØ³Øª."

# -----------------------------------------------------------------------------
# Ø´Ø¨Ù‡â€ŒÚ©Ø¯ Ø¨Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ (Ø¬Ù‡Øª Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ)
# -----------------------------------------------------------------------------

def update_evaluated_prices_job():
    """
    Ø´Ø¨Ù‡â€ŒÚ©Ø¯: Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø§ÛŒØ¯ ØªÙˆØ³Ø· ÛŒÚ© Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ (Scheduler) Ù…Ø§Ù†Ù†Ø¯ Celery ÛŒØ§ Cron
    Ø¨Ù‡ ØµÙˆØ±Øª Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯ ØªØ§ Ù‚ÛŒÙ…Øª Ø®Ø±ÙˆØ¬ Ùˆ Ø³ÙˆØ¯/Ø²ÛŒØ§Ù† Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ Ø±Ø§ Ø¨Ù‡â€ŒØ±ÙˆØ² Ú©Ù†Ø¯.
    """
    logger.info("Ø´Ø±ÙˆØ¹ Ø¬Ø§Ø¨ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„...")
    try:
        # 1. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ ØªÙ…Ø§Ù… Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ Ú©Ù‡ Ù‡Ù†ÙˆØ² Ù‚ÛŒÙ…Øª Ø®Ø±ÙˆØ¬ Ù†Ø¯Ø§Ø±Ù†Ø¯.
        active_signals = WeeklyWatchlistResult.query.filter(
            WeeklyWatchlistResult.status == 'active'
        ).all()
        
        # 2. Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø³ÛŒÚ¯Ù†Ø§Ù„ØŒ Ø¢Ø®Ø±ÛŒÙ† Ù‚ÛŒÙ…Øª Ø±Ø§ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù„ÙˆÚ©Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø¢Ù† Ø±Ø§ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ù†.
        for signal in active_signals:
            try:
                # Ù‚ÛŒÙ…Øª Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù„ÙˆÚ©Ø§Ù„ HistoricalData Ø®ÙˆØ§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
                latest_historical_data = HistoricalData.query.filter_by(
                    symbol_id=signal.symbol_id
                ).order_by(HistoricalData.jdate.desc()).first()

                if not latest_historical_data:
                    logger.warning(f"âŒ Ø¢Ø®Ø±ÛŒÙ† Ø¯Ø§Ø¯Ù‡ ØªØ§Ø±ÛŒØ®ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {signal.symbol_name} ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯.")
                    continue

                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 'close' Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù‚ÛŒÙ…Øª Ø®Ø±ÙˆØ¬ ÛŒÚ©Ù†ÙˆØ§Ø®Øª (Ù…Ø§Ù†Ù†Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡)
                latest_price = getattr(latest_historical_data, 'close', getattr(latest_historical_data, 'close_price', None))

                # ... Ù…Ù†Ø·Ù‚ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ (Ø­Ø¯ Ø³ÙˆØ¯/Ø¶Ø±Ø±) ...
                if latest_price: 
                    signal.exit_price = latest_price 
                    signal.status = 'evaluated' 
                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² _calculate_pnl
                    signal.profit_loss_percentage = _calculate_pnl(signal.entry_price, signal.exit_price)
                    db.session.add(signal)
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù…Ø§Ø¯ {signal.symbol_name}: {e}")
            
        db.session.commit()
        logger.info(f"Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ {len(active_signals)} Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙØ¹Ø§Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
        
    except SQLAlchemyError as e:
        db.session.rollback()
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Ø¬Ø§Ø¨ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ: {e}", exc_info=True)
    except Exception as e:
        db.session.rollback() # Ø¨Ù‡ØªØ± Ø§Ø³Øª Ø¯Ø± Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¨ÛŒØ±ÙˆÙ†ÛŒ Ù‡Ù… rollback Ú©Ù†ÛŒÙ…
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø¬Ø§Ø¨ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ: {e}", exc_info=True)